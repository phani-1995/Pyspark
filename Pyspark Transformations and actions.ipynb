{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour,minute,second,col,avg,when\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as sql_functions\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.csv(\"file:///home/hadoopuser/Downloads/sample1.txt\",header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| id|  name|salary|\n",
      "+---+------+------+\n",
      "|  1|  John| 20000|\n",
      "|  2|Jadhav| 25000|\n",
      "+---+------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#performaing Action\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting total people \n",
    "df1 = df.select('name').count()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|   name|sum(salary)|\n",
      "+-------+-----------+\n",
      "| Jeevan|      35000|\n",
      "|   John|      20000|\n",
      "|Johnson|      30000|\n",
      "| Jadhav|      25000|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"name\").sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "| Jadhav|\n",
      "|Johnson|\n",
      "| Jeevan|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To display names whose salary is greater than 20K\n",
    "df.filter(df['salary'] > 20000).select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the maximum salary \n",
    "df.groupby().max('salary').first().asDict()['max(salary)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Minimum value\n",
    "df.registerTempTable(\"df_table\")\n",
    "spark.sql(\"SELECT MIN(salary) as maxsal FROM df_table\").first().asDict()['maxsal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+-----------------+\n",
      "|summary|                id|   name|           salary|\n",
      "+-------+------------------+-------+-----------------+\n",
      "|  count|                 4|      4|                4|\n",
      "|   mean|               2.5|   null|          27500.0|\n",
      "| stddev|1.2909944487358056|   null|6454.972243679028|\n",
      "|    min|                 1| Jadhav|            20000|\n",
      "|    max|                 4|Johnson|            35000|\n",
      "+-------+------------------+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27500.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding average salary\n",
    "spark.sql(\"SELECT AVG(salary) as avgsal FROM df_table\").first().asDict()['avgsal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
